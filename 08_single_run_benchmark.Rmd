
```{r setup, include=FALSE, echo=FALSE}
require(knitr)
knitr::opts_chunk$set(message=FALSE, warning=FALSE, error=FALSE, fig.height=5, fig.width=8, fig.path="figures/")

require(papaja)
require(kableExtra)
require(dplyr)
require(magrittr)
```



# Single Run Benchmark

In this section, we will measure the performance differences among r, python and stata, specifically the `single_run` function of each software,
which is the atomic function of whole power simulation program.
But, due to the differences of parameters selection, the measurement is not technically subjective, the benchmark results here are for reference only.

## R

In implementation with [R](./r.html), we used all parameters ($\beta_0$, $\beta_1$, $\omega_0$, $\tau_0$, $\tau_1$, $\rho$, $\sigma$) to generate simulated data
and used the function `lmer()` from the package `{lmerTest}` to perform linear mixed effects analyze.

Here are the definitions of functions [sim_data](./r.html#data-simulation-automated) and [single_run](./r.html#power-calculation-single-run).

```{r, eval=TRUE, echo=FALSE, results=FALSE}
pacman::p_load(
  lme4,         # model specification / estimation
  lmerTest,     # provides p-values in the model output
  future,       # parallelization
  future.apply, # fast automation
  furrr,        # fast functional programming
  faux,         # simulate from multivariate normal distribution
  broom.mixed,  # extracting tidy data from model fits
  tidyverse,    # data wrangling and visualisation
  gt            # nice tables
)
faux_options(verbose = FALSE)
set.seed(02138)

plan(multisession)

sim_data <- function(
  n_subj     =  25,   # number of subjects
  n_pop      =  15,   # number of pop songs
  n_rock     =  15,   # number of rock songs
  beta_0     =  60,   # mean for pop genre
  beta_1     =   5,   # effect of genre
  omega_0    =   3,   # by-song random intercept sd
  tau_0      =   7,   # by-subject random intercept sd
  tau_1      =   4,   # by-subject random slope sd
  rho        =   0.2, # correlation between intercept and slope
  sigma      =   8    # residual (standard deviation)
) {
  songs <- tibble(
    song_id = seq_len(n_pop + n_rock),
    category = rep(c("pop", "rock"), c(n_pop, n_rock)),
    genre_i = rep(c(0, 1), c(n_pop, n_rock)),
    O_0i = rnorm(n = n_pop + n_rock, mean = 0, sd = omega_0)
  )

  subjects <- faux::rnorm_multi(
    n = n_subj,
    mu = 0,
    sd = c(tau_0, tau_1),
    r = rho,
    varnames = c("T_0j", "T_1j")
  ) |>
  mutate(subj_id = seq_len(n_subj))

  crossing(subjects, songs) |>
    mutate(e_ij = rnorm(n(), mean = 0, sd = sigma),
         liking_ij = beta_0 + T_0j + O_0i + (beta_1 + T_1j) * genre_i + e_ij) |>
  select(subj_id, song_id, category, genre_i, liking_ij)
}

single_run <- function(...) {
  dat_sim <- sim_data(...)
  mod_sim <- suppressWarnings({ suppressMessages({
    lmerTest::lmer(liking_ij ~ 1 + genre_i + (1 | song_id) + (1 + genre_i | subj_id), data = dat_sim)
  })})
  broom.mixed::tidy(mod_sim)
}
```

We'll use `benchmark` function from package `{rbenchmark}` to measure the running time of function `single_run`.

```{r, eval=TRUE, echo=TRUE, results=TRUE}
library(rbenchmark)

result <- within(
  benchmark(
    single_run = single_run(),
    replications = 100,
    columns = c("test", "elapsed", "replications")
  ),
  {
    average <- elapsed / replications
  }
)

r_average <- result[1, "average"]

sprintf("Average running time is %f s", r_average)
```

## Python

In implementation with [Python](./python.html), we used all parameters ($\beta_0$, $\beta_1$, $\omega_0$, $\tau_0$, $\tau_1$, $\rho$, $\sigma$) to generate simulated data
and used the function `mixedlm()` from package `{statsmodels}` to perform linear mixed effects analyze.

Here are the definitions of functions [sim_data](./python.html#data-simulation-automated) and [single_run](./python.html#power-calculation-single-run).

```{r, eval=TRUE, echo=FALSE, results=FALSE}
require(reticulate)
Sys.setenv(RETICULATE_PYTHON = "C:\\Users\\danyu\\anaconda3\\python.exe")
```

```{python, eval=TRUE, echo=FALSE, results=FALSE}
import statsmodels.formula.api as smf
import numpy as np
import pandas as pd

np.random.seed(2138)

def sim_data(n_subj=25, n_pop=15, n_rock=15, beta_0=60, beta_1=5, omega_0=3, tau_0=7, tau_1=4, rho=0.2, sigma=8):
    songs = pd.DataFrame({
        'song_id': np.arange(n_pop + n_rock),
        'category': np.repeat(["pop", "rock"], [n_pop, n_rock]),
        'genre_i': np.repeat([0, 1], [n_pop, n_rock]),
        'O_0i': np.random.normal(0, omega_0, n_pop + n_rock)
    })

    random_effects = np.random.multivariate_normal([0, 0], [[tau_0**2, rho*tau_0*tau_1], [rho*tau_0*tau_1, tau_1**2]], n_subj)
    subjects = pd.DataFrame(random_effects, columns=['T_0j', 'T_1j'])
    subjects['subj_id'] = np.arange(1, n_subj + 1)

    trials = subjects.assign(key=1).merge(songs.assign(key=1), on='key').drop(columns='key')
    trials['e_ij'] = np.random.normal(0, sigma, len(trials))
    trials['liking_ij'] = beta_0 + trials['T_0j'] + trials['O_0i'] + (beta_1 + trials['T_1j']) * trials['genre_i'] + trials['e_ij']

    return trials[['subj_id', 'song_id', 'category', 'genre_i', 'liking_ij']]

def single_run(n_subj=25, n_pop=15, n_rock=15, beta_0=60, beta_1=5, omega_0=3, tau_0=7, tau_1=4, rho=0.2, sigma=8):
    dat_sim = sim_data(n_subj, n_pop, n_rock, beta_0, beta_1, omega_0, tau_0, tau_1, rho, sigma)

    dat_sim['groups'] = 1
    mod_sim = smf.mixedlm('liking_ij ~ 1 + genre_i', groups=dat_sim['groups'],
                          vc_formula={'song_id':'0 + C(song_id)', 'subj_id':'0 + C(subj_id)', 'genre_i': '0 + C(subj_id):genre_i'},
                          re_formula='0', data=dat_sim).fit()

    df = mod_sim.summary().tables[1]
    df['p_value'] = mod_sim.pvalues
    return df[['Coef.', 'Std.Err.', 'p_value']]
```

We'll use `timeit` function from the package `{timeit}` to measure the running time of function `single_run`.

```{python, eval=TRUE, echo=TRUE, results=TRUE}
import timeit

result = timeit.timeit(single_run, number=100)
python_average = result/100

print(f"Average running time is {python_average} s")
```

## Stata

In implementation with [Stata](./stata.html), we only used 4 parameters ($\beta_0$, $\beta_1$, $\tau_0$, $\sigma$) to generate simulated data
and used the function `mixed` to perform linear mixed effects analyze.

Here are the definitions of functions [sim_data](./stata.html#data-simulation-automated) and [single_run](./stata.html#power-calculation-single-run).

```{r, eval=TRUE, echo=FALSE, results=FALSE}
require(Statamarkdown)
knitr::opts_chunk$set(engine.path=list(stata="C:/Program Files/Stata18/StataMP-64.exe"))
```

```{stata, collectcode=TRUE, eval=TRUE, echo=FALSE, results=FALSE}
clear all
set seed 02138

capture program drop sim_data
program define sim_data
	args n_subj n_pop n_rock beta_0 beta_1 tau_0 sigma

	clear
	local n_all = `n_pop' + `n_rock'
	set obs `n_all'
	gen song_id = _n
	gen category = "pop"
	replace category = "rock" if song_id > `n_pop'
	gen genre_i = 0
	replace genre_i = 1 if song_id > `n_pop'
	gen key = 1
	save "./data/songs.dta", replace

	clear
	set obs `n_subj'

	gen t0 = rnormal(0, `tau_0')
	gen subj_id = _n
	gen key = 1
	save "./data/subjects.dta", replace

	use "./data/subjects.dta"
	cross using "./data/songs.dta"
	drop key
	sort subj_id song_id
	gen e_ij = rnormal(0, `sigma')

	gen liking_ij = `beta_0' + t0 + `beta_1' * genre_i + e_ij
	keep subj_id song_id category genre_i liking_ij
end

capture program drop single_run
program define single_run, rclass
	args n_subj n_pop n_rock beta_0 beta_1 tau_0 sigma

	clear
	sim_data `n_subj' `n_pop' `n_rock' `beta_0' `beta_1' `tau_0' `sigma'
	mixed liking_ij genre_i || subj_id:, noretable nofetable noheader nogroup

  estimates clear
	estimates store model_results

	matrix coefficients = e(b)
	matrix std_errors = e(V)
	matrix p_values = e(p)

	return scalar coef = coefficients[1, 1]
	return scalar std_err = std_errors[1, 1]
	return scalar p_value = p_values[1, 1]
end
```

In stata, we have to implement the benchmark code by our own.

```{stata, collectcode=FALSE, eval=TRUE, echo=TRUE, results=TRUE}
capture program drop tstart
program tstart, rclass
  timer clear 1
  timer on 1
end

capture program drop tend
program tend, rclass
  timer off 1
  qui timer list 1
  scalar r = r(t1)
end

tstart
quietly {
    forval i = 1/100 {
        single_run 25 15 15 60 5 7 8
    }
}
tend
local result = scalar(r)
local stata_average = r / 100
di "Average running time is " `stata_average' " s"

quietly {
    file open result using "./data/stata_average.txt", write replace
    set more off

    file write result "`stata_average'"
    file close result
    set more on
}
```

## Benchmark Results

Finally, we get all the results of r, python and stata, let's show them with a table.

```{r, eval=TRUE, echo=FALSE, results='axis'}
stata_average <- as.double(paste(readLines("./data/stata_average.txt")))

tibble::tribble(
    ~`Software`, ~`Parameters`, ~`Average Time`,
    "R", "$\\beta_0$, $\\beta_1$, $\\omega_0$, $\\tau_0$, $\\tau_1$, $\\rho$, $\\sigma$", r_average,
    "Python", "$\\beta_0$, $\\beta_1$, $\\omega_0$, $\\tau_0$, $\\tau_1$, $\\rho$, $\\sigma$", py$python_average,
    "Stata", "$\\beta_0$, $\\beta_1$, $\\tau_0$, $\\sigma$", stata_average
) %>%
    apa_table(
        align = c("l", "l", "l"),
        caption = "Benchmark results.",
        escape = FALSE
    )
```